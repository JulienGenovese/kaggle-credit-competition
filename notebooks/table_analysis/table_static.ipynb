{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE STATIC ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is composed by 3 tables:\n",
    "\n",
    "- <code>train_static_0_0</code>, <code>train_static_0_1</code> that are internal data frames of home credit.\n",
    "- <code>train_tatic_cb_0</code> that is an external dataset.\n",
    "\n",
    "We are mainly interested in the internal datasets since we will have to do a stable inference in a future and a not sure table cannot be a good predictor with this goal.\n",
    "\n",
    "We will analyze this points:\n",
    "\n",
    "- the columns of all dataframes\n",
    "- how to merge them\n",
    "- their NA meanings and how to fill them\n",
    "- some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! From https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/476463 we can see that the person age must be taken from train_person_1 \"birth_259D\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.utils import get_feature_definitions, compute_date_distance_from_col, extract_columns_tipe, aggregate_num_features_by_historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the target dataframe with the features definition in order to improve the graphics later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pl.read_parquet(dataPath + 'parquet_files/train/train_base.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_definition = pl.read_csv(dataPath + 'feature_definitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_0_0 = pl.read_parquet(dataPath + \"parquet_files/train/train_static_0_0.parquet\")\n",
    "train_static_0_1 = pl.read_parquet(dataPath + \"parquet_files/train/train_static_0_1.parquet\")\n",
    "train_static_cb_1 = pl.read_parquet(dataPath + \"parquet_files/train/train_static_cb_0.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. STRUCTURE OF THE DATAFRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see how the dataframe are made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003757, 168)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static_0_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522902, 168)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static_0_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500476, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static_cb_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite clear that the esternal dataframe has a different structure. \n",
    "\n",
    "In this first analys as we have said we will only analyze the internal dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. INTERNAL DATA SOURCE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see if the internal datasources have the same columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_0_0 = list(train_static_0_0.columns)\n",
    "columns_0_1 = list(train_static_0_1.columns)\n",
    "\n",
    "columns_0_0.sort()\n",
    "columns_0_1.sort()\n",
    "\n",
    "columns_0_0 == columns_0_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframe have the same columns but different rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go in more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case id in first dataframe:  1003757\n",
      "The case id are unique in the first dataframe:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of case id in first dataframe: \", train_static_0_0[\"case_id\"].n_unique())\n",
    "print(\"The case id are unique in the first dataframe: \", train_static_0_0[\"case_id\"].n_unique() == train_static_0_0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case id in second dataframe:  522902\n",
      "The case id are unique in the second dataframe:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of case id in second dataframe: \", train_static_0_1[\"case_id\"].n_unique())\n",
    "print(\"The case id are unique in the second dataframe: \", train_static_0_1[\"case_id\"].n_unique() == train_static_0_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each case id in the dataframes is unique.\n",
    "\n",
    "Let's see if the two dataframe have some case id in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_static_0_1[\"case_id\"].unique()).intersection(set(train_static_0_0[\"case_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can conclude that we have two perfectly separated dataframes with each one its case ids and with the same columns. We can concated them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal = pl.concat(\n",
    "    [\n",
    "        train_static_0_0, \n",
    "        train_static_0_1,\n",
    "    ],\n",
    "    how=\"vertical_relaxed\", how=\"vertical_relaxed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DEEPER ANALYSIS ON THE COMPLETE INTERNAL TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move to a deeper analysis on the entire dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pandas representation in order to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd = train_static_internal.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 COLUMNS TYPE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the column types splitted by tipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num, features_date, features_cat = extract_columns_tipe(train_static_internal_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgenovese/anaconda3/envs/kaggle_competition/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config() as cfg:\n",
    "    cfg.set_fmt_str_lengths(150)\n",
    "    cfg.set_tbl_rows(-1)\n",
    "\n",
    "    display(get_feature_definitions(features_date, df_feature_definition)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_date:\n",
    "    train_static_internal = train_static_internal.with_columns(pl.col(col).str.to_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.with_columns(pl.col(\"date_decision\").str.to_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config() as cfg:\n",
    "    cfg.set_fmt_str_lengths(150)\n",
    "    cfg.set_tbl_rows(-1)\n",
    "\n",
    "    display(get_feature_definitions(features_num, df_feature_definition)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 NULL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = (train_static_internal.null_count() / train_static_internal.shape[0]).transpose(include_header=True).sort(by=\"column_0\", descending=True).to_pandas()\n",
    "df_nulls[\"perc_of_nulls\"] = df_nulls.iloc[:, 1] \n",
    "df_nulls = df_nulls.drop(\"column_0\", axis = 1)\n",
    "df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in case of a lot of null it seems this is a information. We have to understand how to deal with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls[\"perc_of_nulls\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls.loc[(df_nulls[\"perc_of_nulls\"] < 0.8) & (df_nulls[\"perc_of_nulls\"]>0.6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seems in this case as well that the absence of the value is an information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 ANALYSIS OF CATEGORICAL VS NUMERICAL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first want to split the numerical variable from the cathegorical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_cat:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the date column we can see that we will need to compute a difference between a reference time and the considered date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aesthetics\n",
    "default_color_1 = 'darkblue'\n",
    "default_color_2 = 'darkgreen'\n",
    "default_color_3 = 'darkred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd = train_static_internal_pd.merge(df_target, on='case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much values are unique in the numerical and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features_num:\n",
    "    print(col, \": \", len(train_static_internal_pd[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = []\n",
    "long_features_cat = []\n",
    "short_features_cat = []\n",
    "for col in features_cat:\n",
    "    if 'date' in col or col.endswith(\"D\"):\n",
    "        date_columns.append(col)\n",
    "        features_cat.remove(col)\n",
    "    elif len(train_static_internal_pd[col].unique()) > 10:\n",
    "        long_features_cat.append(col)\n",
    "    elif len(train_static_internal_pd[col].unique()) <= 10:\n",
    "        short_features_cat.append(col)\n",
    "    else: \n",
    "        raise ValueError(\"Strange column: \", col)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in long_features_cat:\n",
    "    print(col, \": \", len(train_static_internal_pd[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in short_features_cat:\n",
    "    print(col, \": \", len(train_static_internal_pd[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"isdebitcard_729L\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"isbidproductrequest_292L\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"paytype_783L\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"typesuite_864L\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"bankacctype_710L\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_internal_pd[\"isbidproduct_1095L\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a very big difference among the variable cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continuous(df, feature, txt):\n",
    "    '''Plot a histogram and boxplot for the churned and retained distributions for the specified feature.'''\n",
    "    df_func = df.copy()\n",
    "    df_paid = df.loc[df[\"target\"] == 1]\n",
    "    df_default = df.loc[df[\"target\"] == 0]\n",
    "    \n",
    "    df_func['target'] = df_func['target'].astype('category')\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    for df, label in zip([df_paid,df_default], [0, 1]): \n",
    "        sns.boxplot(data=df,\n",
    "                     x=feature,\n",
    "                     bins=30,\n",
    "                     alpha=0.66,\n",
    "                     edgecolor='firebrick',\n",
    "                     label=label,\n",
    "                     kde=False,\n",
    "                     ax=ax1)\n",
    "    ax1.legend()\n",
    "    fig.text(.5, .005, txt, ha='center')\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical(df, feature, txt):\n",
    "    '''For a categorical feature, plot a seaborn.countplot for the total counts of each category next to a barplot for the churn rate.'''\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    sns.countplot(x=feature,\n",
    "                  hue='target',\n",
    "                  data=df,\n",
    "                  ax=ax1)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.legend(labels=['paid', 'default'])\n",
    "    ax1.tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    fig.text(.5, .005, txt, ha='center')\n",
    "    plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in short_features_cat:\n",
    "    print(i)\n",
    "    plot_categorical(train_static_internal_pd, i, f'({dict_feature[i]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. FEATURE CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_with_static = df_target.join(other=train_static_internal, left_on=\"case_id\", right_on=\"case_id\", how=\"left\")  \n",
    "df_target_with_static, diff_col = compute_date_distance_from_col(df_target_with_static, features_date, \"date_decision\")\n",
    "df_target_with_static= df_target_with_static.drop(features_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataframe we can conclude that on a first glance, the internal dataset has a good quality.\n",
    "\n",
    "We only have to take into account that:\n",
    "\n",
    "- The NAs seem informative and so we don't have to drop them. \n",
    "- We don't know nothing about the outlier values at the moment. Maybe they are informative so we will not drop them.\n",
    "- the date can be used to compute a time difference. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
