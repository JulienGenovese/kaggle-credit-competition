{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.modeling import find_best_ensemble, predict_proba_in_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and data loading\n",
    "\n",
    "- Load test set (during inference on kaggle we'll have the full dataset)\n",
    "- Combine with static features and filter using columns used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup\n",
    "ROOT = '..'\n",
    "EXTENSION = 'parquet'\n",
    "DATA_FOLDER = 'data'\n",
    "MODEL_FOLDER = 'models'\n",
    "OUTPUT_FOLDER = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57543</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57549</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id date_decision   MONTH  WEEK_NUM\n",
       "0    57543    2020-10-06  202010        92\n",
       "1    57549    2020-10-06  202010        92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet(f'{ROOT}/{DATA_FOLDER}/test/test_base.{EXTENSION}')\n",
    "test['date_decision'] = pd.to_datetime(test['date_decision'])\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = pd.read_csv(f'{ROOT}/{DATA_FOLDER}/{OUTPUT_FOLDER}/columns_to_keep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>actualdpdtolerance_344P</th>\n",
       "      <th>amtinstpaidbefduel24m_4187115A</th>\n",
       "      <th>annuity_780A</th>\n",
       "      <th>annuitynextmonth_57A</th>\n",
       "      <th>applicationcnt_361L</th>\n",
       "      <th>applications30d_658L</th>\n",
       "      <th>applicationscnt_1086L</th>\n",
       "      <th>...</th>\n",
       "      <th>pmtnum_254L</th>\n",
       "      <th>posfpd10lastmonth_333P</th>\n",
       "      <th>posfpd30lastmonth_3976960P</th>\n",
       "      <th>posfstqpd30lastmonth_3976962P</th>\n",
       "      <th>price_1097A</th>\n",
       "      <th>sellerplacecnt_915L</th>\n",
       "      <th>sellerplacescnt_216L</th>\n",
       "      <th>sumoutstandtotal_3546847A</th>\n",
       "      <th>totaldebt_9A</th>\n",
       "      <th>totalsettled_863A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57543</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7637.20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57549</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>902.60004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57551</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3610.20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57552</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6964.40000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57569</td>\n",
       "      <td>202010</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5553.40000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id   MONTH  WEEK_NUM  actualdpdtolerance_344P  \\\n",
       "0    57543  202010        92                      NaN   \n",
       "1    57549  202010        92                      NaN   \n",
       "2    57551  202010        92                      NaN   \n",
       "3    57552  202010        92                      NaN   \n",
       "4    57569  202010        92                      NaN   \n",
       "\n",
       "   amtinstpaidbefduel24m_4187115A  annuity_780A  annuitynextmonth_57A  \\\n",
       "0                             NaN    7637.20000                   0.0   \n",
       "1                             NaN     902.60004                   0.0   \n",
       "2                             NaN    3610.20000                   0.0   \n",
       "3                             NaN    6964.40000                   0.0   \n",
       "4                             NaN    5553.40000                   0.0   \n",
       "\n",
       "   applicationcnt_361L  applications30d_658L  applicationscnt_1086L  ...  \\\n",
       "0                  0.0                   0.0                    0.0  ...   \n",
       "1                  0.0                   0.0                    0.0  ...   \n",
       "2                  0.0                   0.0                    0.0  ...   \n",
       "3                  0.0                   0.0                    0.0  ...   \n",
       "4                  0.0                   0.0                    0.0  ...   \n",
       "\n",
       "   pmtnum_254L  posfpd10lastmonth_333P  posfpd30lastmonth_3976960P  \\\n",
       "0         36.0                     0.0                         0.0   \n",
       "1         12.0                     0.0                         0.0   \n",
       "2         12.0                     0.0                         0.0   \n",
       "3         18.0                     0.0                         0.0   \n",
       "4         11.0                     0.0                         0.0   \n",
       "\n",
       "   posfstqpd30lastmonth_3976962P  price_1097A  sellerplacecnt_915L  \\\n",
       "0                            0.0          0.0                  0.0   \n",
       "1                            1.0          NaN                  0.0   \n",
       "2                            0.0          NaN                  0.0   \n",
       "3                            0.0          NaN                  0.0   \n",
       "4                            0.0          NaN                  0.0   \n",
       "\n",
       "   sellerplacescnt_216L  sumoutstandtotal_3546847A  totaldebt_9A  \\\n",
       "0                   1.0                        NaN           0.0   \n",
       "1                   0.0                        NaN           0.0   \n",
       "2                   1.0                        NaN           0.0   \n",
       "3                   0.0                        NaN           0.0   \n",
       "4                   0.0                        NaN           0.0   \n",
       "\n",
       "   totalsettled_863A  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import static features\n",
    "test_static_0 = pd.read_parquet(f'{ROOT}/{DATA_FOLDER}/test/test_static_0_0.{EXTENSION}')\n",
    "test_static_1 = pd.read_parquet(f'{ROOT}/{DATA_FOLDER}/test/test_static_0_1.{EXTENSION}')\n",
    "test_static_concat = pd.concat([test_static_0, test_static_1])\n",
    "\n",
    "# Importing columns to keep\n",
    "columns_to_keep = pd.read_csv(f'{ROOT}/{DATA_FOLDER}/{OUTPUT_FOLDER}/columns_to_keep.csv')['cols'].tolist()\n",
    "\n",
    "test_merged = test.merge(test_static_concat, on='case_id', validate='1:1')\n",
    "test_merged = test_merged.loc[:, columns_to_keep]\n",
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_merged.drop(['case_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hill climbing: use OOF files to find best weights\n",
    "\n",
    "- Load OOF files and models used during training\n",
    "- Start with the best model in terms of predictive power\n",
    "- Iteratively test weights until new best score is found (if any)\n",
    "- Compare new best score with previous one\n",
    "- If new best is better (+ tolerance), save the weight and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2 oof files...\n",
      "We have 2 models...\n",
      "\n",
      "['oof_lgb_1_202402201134.csv' 'oof_xb_1_202402201134.csv']\n",
      "['lgb_1_202402201134.pkl' 'xb_1_202402201134.pkl']\n"
     ]
    }
   ],
   "source": [
    "OOF = np.sort( [f for f in os.listdir('{}/{}/{}'.format(ROOT, DATA_FOLDER, OUTPUT_FOLDER)) if 'oof' in str(f)] )\n",
    "MODELS = np.sort( [f for f in os.listdir('{}/{}/{}'.format(ROOT, DATA_FOLDER, MODEL_FOLDER))] )\n",
    "OOF_CSV = [pd.read_csv('{}/{}/{}/{}'.format(ROOT, DATA_FOLDER, OUTPUT_FOLDER, k)) for k in OOF]\n",
    "MODELS_LOAD = [joblib.load('{}/{}/{}/{}'.format(ROOT, DATA_FOLDER, MODEL_FOLDER, k)) for k in MODELS]\n",
    "\n",
    "print('We have %i oof files...'%len(OOF))\n",
    "print('We have %i models...'%len(MODELS))\n",
    "print(); print(OOF); print(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 has AUC 0.7864\n",
      "Model 1 has AUC 0.7802\n"
     ]
    }
   ],
   "source": [
    "oof_scores = []\n",
    "truth_values = None\n",
    "for i, (file, model) in enumerate(zip(OOF_CSV, MODELS)):\n",
    "    if truth_values is None:\n",
    "        truth_values = file['truth']\n",
    "    score = roc_auc_score(file['truth'], file['oof'])\n",
    "    oof_scores.append(score)\n",
    "    print('Model {} has AUC {:.4f}'.format(i, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best initial model\n",
    "initial_best_index = np.argmax(oof_scores)\n",
    "initial_best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best model to add... \n",
      "0 , 1 , \n",
      "\n",
      "No further improvements. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# Build the first ensemble...\n",
    "current_score = roc_auc_score(truth_values, OOF_CSV[initial_best_index].oof)\n",
    "best_weights = [1]\n",
    "best_models = [initial_best_index]\n",
    "current_ensemble = OOF_CSV[initial_best_index].oof\n",
    "\n",
    "# ...and perform iteratively the model search using find_best_ensemble function\n",
    "for _ in range(len(OOF)):\n",
    "    best_weight, best_model, best_score = find_best_ensemble(current_ensemble=current_ensemble,\n",
    "                                                             best_models=best_models, \n",
    "                                                             oof_files=OOF,\n",
    "                                                             oof_csv=OOF_CSV,\n",
    "                                                             truth=truth_values)\n",
    "    print()\n",
    "    if best_score - current_score < 0.003: # If there are no significant improvements, stop the search\n",
    "        print()\n",
    "        print('No further improvements. Stopping.')\n",
    "        break\n",
    "    \n",
    "    print()\n",
    "    print('Ensemble AUC {:.4f} after adding model {} with weight {}. Increase of {:.4f}'.format(best_score, best_model,\n",
    "                                                                                                best_weight, best_score - current_score))\n",
    "    \n",
    "    current_ensemble = best_weight * current_ensemble + (1-best_weight) * OOF_CSV[best_model].oof\n",
    "    current_score = best_score\n",
    "    \n",
    "    best_weights.append(best_weight)\n",
    "    best_models.append(best_model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using models [0]\n",
      "with weights [1]\n",
      "and achieve ensemble AUC = 0.78637\n"
     ]
    }
   ],
   "source": [
    "print('We are using models', best_models)\n",
    "print('with weights', best_weights)\n",
    "print('and achieve ensemble AUC = %.5f'% current_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction\n",
    "\n",
    "- Given the best weights and models from previous step, get the first prediction using starting model\n",
    "- Iterate over the list of models and weights found previously and ensemble the predictions\n",
    "- Use predict in batch to avoid predicting on large dataset (which is going to happen during submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting initial predictions\n",
      "Processing batch: 1/1\n",
      "\n",
      "Iterating over models and weights to ensemble\n",
      "\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.42952113, 0.53824271, 0.38161238, 0.40126   , 0.26709266,\n",
       "       0.28235209, 0.33220087, 0.25758381, 0.49248294, 0.52387615])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Getting initial predictions')\n",
    "current_prediction = predict_proba_in_batches(MODELS_LOAD[best_models[0]], x)\n",
    "\n",
    "print('\\nIterating over models and weights to ensemble')\n",
    "for model, weight in zip(best_models[1:], best_weights[1:]):\n",
    "    current_prediction = weight * current_prediction + (1-weight) * predict_proba_in_batches(MODELS_LOAD[model], x)\n",
    "\n",
    "print('\\nDone')\n",
    "\n",
    "current_prediction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Kaggle we'll add the predictions to the score column in the submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
